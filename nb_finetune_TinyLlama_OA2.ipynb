{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f650484c-467e-4d89-93ba-6a3158f53f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "accelerate==0.26.1\n",
      "addict==2.4.0\n",
      "aenum==3.1.15\n",
      "aiofiles==23.1.0\n",
      "aiohttp==3.8.5\n",
      "aiosignal==1.3.1\n",
      "altair==5.1.1\n",
      "annotated-types==0.6.0\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==3.7.1\n",
      "apache-beam==2.52.0\n",
      "appdirs==1.4.4\n",
      "apturl==0.5.2\n",
      "argon2-cffi==23.1.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.3.0\n",
      "asttokens==2.4.1\n",
      "astunparse==1.6.3\n",
      "async-lru==2.0.4\n",
      "async-timeout==4.0.3\n",
      "attributedict==0.3.0\n",
      "attrs==23.1.0\n",
      "autoawq==0.1.8\n",
      "Babel==2.13.1\n",
      "basicsr==1.4.2\n",
      "bcrypt==3.2.0\n",
      "beautifulsoup4==4.10.0\n",
      "beniget==0.4.1\n",
      "bitsandbytes==0.42.0\n",
      "bleach==6.1.0\n",
      "blendmodes==2022\n",
      "blessings==1.7\n",
      "blinker==1.4\n",
      "boltons==23.0.0\n",
      "bottle==0.12.19\n",
      "Brlapi==0.8.3\n",
      "Brotli==1.1.0\n",
      "cached-property==1.5.2\n",
      "cachetools==5.3.2\n",
      "cattrs==23.2.3\n",
      "causal-conv1d==1.0.0\n",
      "certifi==2023.11.17\n",
      "cffi==1.16.0\n",
      "chardet==5.2.0\n",
      "charset-normalizer==3.2.0\n",
      "ci-info==0.3.0\n",
      "clean-fid==0.1.35\n",
      "click==7.1.2\n",
      "clip @ https://github.com/openai/CLIP/archive/d50d76daa670286dd6cacf3bcd80b5e4823fc8e1.zip\n",
      "cloudpickle==2.2.1\n",
      "cmake==3.27.4.1\n",
      "codecov==2.1.13\n",
      "colorama==0.4.6\n",
      "coloredlogs==15.0.1\n",
      "colour-runner==0.1.1\n",
      "comm==0.1.4\n",
      "command-not-found==0.3\n",
      "configobj==5.0.8\n",
      "configparser==6.0.0\n",
      "controlnet-aux==0.0.7\n",
      "coolgpus==0.23\n",
      "coverage==7.4.0\n",
      "crcmod==1.7\n",
      "cryptography==41.0.7\n",
      "cssselect2==0.7.0\n",
      "cuda-python==12.2.0\n",
      "cupshelpers==1.0\n",
      "cycler==0.11.0\n",
      "Cython==3.0.3\n",
      "dataclasses-json==0.6.3\n",
      "DataProperty==1.0.1\n",
      "datasets==2.16.1\n",
      "dbus-python==1.2.18\n",
      "debugpy==1.8.0\n",
      "decorator==4.4.2\n",
      "deepdiff==6.7.1\n",
      "defer==1.0.6\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.14\n",
      "deprecation==2.1.0\n",
      "diffusers==0.23.1\n",
      "dill==0.3.7\n",
      "diskcache==5.6.3\n",
      "distlib==0.3.8\n",
      "distro==1.7.0\n",
      "distro-info==1.1+ubuntu0.1\n",
      "dnspython==2.4.2\n",
      "docker==5.0.3\n",
      "docker-pycreds==0.4.0\n",
      "docopt==0.6.2\n",
      "duplicity==0.8.21\n",
      "einops==0.4.1\n",
      "etelemetry==0.3.1\n",
      "evaluate==0.4.0\n",
      "exceptiongroup==1.1.3\n",
      "execnb==0.1.5\n",
      "executing==2.0.1\n",
      "facexlib==0.3.0\n",
      "fastapi==0.109.0\n",
      "fastavro==1.8.3\n",
      "fastcore==1.5.29\n",
      "fasteners==0.14.1\n",
      "fastjsonschema==2.18.1\n",
      "fastlangid==1.0.11\n",
      "fasttext==0.9.2\n",
      "ffmpy==0.3.1\n",
      "filelock==3.13.1\n",
      "filterpy==1.4.5\n",
      "fitz==0.0.1.dev2\n",
      "flash-attn==2.4.2\n",
      "flatbuffers==23.5.26\n",
      "fonttools==4.29.1\n",
      "fqdn==1.5.1\n",
      "frontend==0.0.3\n",
      "frozenlist==1.4.0\n",
      "fs==2.4.12\n",
      "fsspec==2023.6.0\n",
      "ftfy==6.1.3\n",
      "future==0.18.2\n",
      "fvcore==0.1.5.post20221221\n",
      "gast==0.5.2\n",
      "gdown==4.7.1\n",
      "gfpgan==1.3.8\n",
      "ghapi==1.0.4\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.32\n",
      "Glances==3.2.4.2\n",
      "google-auth==2.23.0\n",
      "google-auth-oauthlib==1.0.0\n",
      "gradio==3.41.2\n",
      "gradio_client==0.5.0\n",
      "greenlet==3.0.3\n",
      "grpcio==1.58.0\n",
      "h11==0.12.0\n",
      "hdfs==2.7.2\n",
      "hjson==3.1.0\n",
      "html5lib==1.1\n",
      "httpcore==0.15.0\n",
      "httplib2==0.20.2\n",
      "httpx==0.24.1\n",
      "huggingface-hub==0.19.4\n",
      "humanfriendly==10.0\n",
      "idna==3.3\n",
      "imageio==2.31.5\n",
      "img2pdf==0.5.1\n",
      "immutabledict==3.0.0\n",
      "importlib-metadata==6.8.0\n",
      "importlib-resources==6.1.0\n",
      "inflate64==1.0.0\n",
      "inflection==0.5.1\n",
      "influxdb==5.3.1\n",
      "inquirerpy==0.3.4\n",
      "inspecta==0.1.3\n",
      "iopath==0.1.9\n",
      "ipykernel==6.26.0\n",
      "ipyplot==1.1.1\n",
      "ipython==8.17.2\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==8.0.4\n",
      "isodate==0.6.1\n",
      "isoduration==20.11.0\n",
      "itsdangerous==2.1.2\n",
      "jedi==0.19.1\n",
      "jeepney==0.7.1\n",
      "Jinja2==3.1.2\n",
      "joblib==1.3.2\n",
      "Js2Py==0.74\n",
      "json5==0.9.14\n",
      "jsonlines==4.0.0\n",
      "jsonmerge==1.8.0\n",
      "jsonpatch==1.33\n",
      "jsonpointer==2.4\n",
      "jsonschema==4.19.0\n",
      "jsonschema-specifications==2023.7.1\n",
      "jupyter==1.0.0\n",
      "jupyter-console==6.6.3\n",
      "jupyter-events==0.8.0\n",
      "jupyter-lsp==2.2.0\n",
      "jupyter_client==8.5.0\n",
      "jupyter_core==5.5.0\n",
      "jupyter_server==2.9.1\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab==4.0.8\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_server==2.25.0\n",
      "kaggle==1.6.3\n",
      "keyring==23.5.0\n",
      "kiwisolver==1.3.2\n",
      "kornia==0.6.7\n",
      "langchain==0.1.0\n",
      "langchain-community==0.0.10\n",
      "langchain-core==0.1.8\n",
      "langcodes==3.3.0\n",
      "langdetect==1.0.9\n",
      "langsmith==0.0.77\n",
      "language-selector==0.1\n",
      "lark==1.1.2\n",
      "launchpadlib==1.10.16\n",
      "lazr.restfulclient==0.14.4\n",
      "lazr.uri==1.0.6\n",
      "lazy_loader==0.3\n",
      "lightning-utilities==0.9.0\n",
      "linkify-it-py==2.0.2\n",
      "lit==16.0.6\n",
      "littleutils==0.2.2\n",
      "llama-cpp-python==0.1.84\n",
      "llvmlite==0.41.0\n",
      "-e git+https://github.com/EleutherAI/lm-evaluation-harness@b69ca72ec3a0294638382e0f90cf32f90d761b44#egg=lm_eval\n",
      "lmdb==1.4.1\n",
      "lockfile==0.12.2\n",
      "loguru==0.6.0\n",
      "looseversion==1.3.0\n",
      "louis==3.20.0\n",
      "lpips==0.1.4\n",
      "lxml==4.8.0\n",
      "lz4==3.1.3+dfsg\n",
      "macaroonbakery==1.3.1\n",
      "Mako==1.1.3\n",
      "mamba-ssm==1.0.1\n",
      "Markdown==3.4.4\n",
      "markdown-it-py==2.2.0\n",
      "MarkupSafe==2.1.3\n",
      "marshmallow==3.20.1\n",
      "matplotlib==3.5.1\n",
      "matplotlib-inline==0.1.6\n",
      "mbstrdecoder==1.1.3\n",
      "mdit-py-plugins==0.3.3\n",
      "mdurl==0.1.2\n",
      "mediapipe==0.10.8\n",
      "mistune==3.0.2\n",
      "monotonic==1.6\n",
      "more-itertools==8.10.0\n",
      "mpmath==0.0.0\n",
      "msgpack==1.0.3\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.15\n",
      "multivolumefile==0.2.3\n",
      "mypy-extensions==1.0.0\n",
      "nbclient==0.8.0\n",
      "nbconvert==7.10.0\n",
      "nbdev==2.3.13\n",
      "nbformat==5.9.2\n",
      "nest-asyncio==1.5.8\n",
      "netifaces==0.11.0\n",
      "networkx==3.1\n",
      "nibabel==5.2.0\n",
      "ninja==1.11.1\n",
      "nipype==1.8.6\n",
      "nltk==3.8.1\n",
      "notebook==7.0.6\n",
      "notebook_shim==0.2.3\n",
      "npm==0.1.1\n",
      "numba==0.58.0\n",
      "numexpr==2.8.7\n",
      "numpy==1.26.3\n",
      "nvidia-cublas-cu12==12.1.3.1\n",
      "nvidia-cuda-cupti-cu12==12.1.105\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-cuda-runtime-cu12==12.1.105\n",
      "nvidia-cudnn-cu12==8.9.2.26\n",
      "nvidia-cufft-cu12==11.0.2.54\n",
      "nvidia-curand-cu12==10.3.2.106\n",
      "nvidia-cusolver-cu12==11.4.5.107\n",
      "nvidia-cusparse-cu12==12.1.0.106\n",
      "nvidia-nccl-cu12==2.18.1\n",
      "nvidia-nvjitlink-cu12==12.2.140\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "oauthlib==3.2.0\n",
      "objsize==0.6.1\n",
      "ocrmypdf==15.4.0\n",
      "olefile==0.46\n",
      "omegaconf==2.2.3\n",
      "open-clip-torch==2.23.0\n",
      "openai==1.3.6\n",
      "openai-whisper @ git+https://github.com/openai/whisper.git@f6f01c561c45ad6ab421405e18ae22fd0c698e92\n",
      "opencv-contrib-python==4.8.1.78\n",
      "opencv-python==4.8.1.78\n",
      "optimum==1.12.0\n",
      "optional-django==0.1.0\n",
      "ordered-set==4.1.0\n",
      "orjson==3.9.7\n",
      "outcome==1.3.0.post0\n",
      "overrides==7.4.0\n",
      "packages==0.1.1\n",
      "packaging==23.2\n",
      "pandas==2.1.4\n",
      "pandocfilters==1.5.0\n",
      "paramiko==2.9.3\n",
      "parso==0.8.3\n",
      "pathlib==1.0.1\n",
      "pathtools==0.1.2\n",
      "pathvalidate==3.2.0\n",
      "pdfminer.six==20231228\n",
      "peft==0.7.1\n",
      "pexpect==4.8.0\n",
      "pfzy==0.3.4\n",
      "piexif==1.1.3\n",
      "pikepdf==8.11.2\n",
      "pillow==10.2.0\n",
      "platformdirs==4.1.0\n",
      "pluggy==1.3.0\n",
      "ply==3.11\n",
      "portalocker==2.8.2\n",
      "prometheus-client==0.18.0\n",
      "prompt-toolkit==3.0.39\n",
      "proto-plus==1.22.3\n",
      "protobuf==3.20.3\n",
      "prov==2.0.0\n",
      "psutil==5.9.5\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "py7zr==0.20.8\n",
      "pyarrow==11.0.0\n",
      "pyarrow-hotfix==0.6\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.3.0\n",
      "pybcj==1.0.2\n",
      "pybind11==2.11.1\n",
      "pycairo==1.20.1\n",
      "pycountry==22.3.5\n",
      "pycparser==2.21\n",
      "pycryptodomex==3.20.0\n",
      "pycups==2.0.1\n",
      "pydantic==2.5.3\n",
      "pydantic-settings==2.1.0\n",
      "pydantic_core==2.14.6\n",
      "pydeck==0.8.1b0\n",
      "pydot==1.4.2\n",
      "pydub==0.25.1\n",
      "Pygments==2.16.1\n",
      "PyGObject==3.42.1\n",
      "pyjsparser==2.7.1\n",
      "PyJWT==2.3.0\n",
      "pymacaroons==0.13.0\n",
      "pymongo==3.13.0\n",
      "PyMuPDF==1.23.8\n",
      "PyMuPDFb==1.23.7\n",
      "PyNaCl==1.5.0\n",
      "pynvml==11.5.0\n",
      "pyparsing==2.4.7\n",
      "pypdfium2==4.25.0\n",
      "pyppmd==1.1.0\n",
      "pyproject-api==1.6.1\n",
      "pyRFC3339==1.1\n",
      "pysmi==0.3.2\n",
      "pysnmp==4.4.12\n",
      "PySocks==1.7.1\n",
      "pyspellchecker==0.7.3\n",
      "pystache==0.6.0\n",
      "pytablewriter==1.2.0\n",
      "python-apt==2.4.0+ubuntu2\n",
      "python-dateutil==2.8.2\n",
      "python-debian==0.1.43+ubuntu1.1\n",
      "python-dotenv==1.0.0\n",
      "python-json-logger==2.0.7\n",
      "python-magic==0.4.27\n",
      "python-multipart==0.0.6\n",
      "python-rapidjson==1.14\n",
      "python-slugify==8.0.1\n",
      "pythran==0.10.0\n",
      "pytils==0.4.1\n",
      "pytorch-lightning==1.9.4\n",
      "pytz==2022.1\n",
      "PyWavelets==1.4.1\n",
      "pyxdg==0.27\n",
      "pyxnat==1.6\n",
      "PyYAML==6.0.1\n",
      "pyzmq==25.1.1\n",
      "pyzstd==0.15.9\n",
      "qtconsole==5.4.4\n",
      "QtPy==2.4.1\n",
      "rapidfuzz==3.6.1\n",
      "ray==2.9.0\n",
      "rdflib==7.0.0\n",
      "realesrgan==0.3.0\n",
      "redis==3.5.3\n",
      "referencing==0.30.2\n",
      "regex==2023.8.8\n",
      "reportlab==3.6.8\n",
      "requests==2.31.0\n",
      "requests-cache==0.5.2\n",
      "requests-oauthlib==1.3.1\n",
      "resize-right==0.0.2\n",
      "responses==0.18.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rich==13.7.0\n",
      "rootpath==0.1.1\n",
      "rouge==1.0.1\n",
      "rouge-score==0.1.2\n",
      "rpds-py==0.10.2\n",
      "rsa==4.9\n",
      "sacrebleu==1.5.0\n",
      "safetensors==0.3.1\n",
      "scikit-image==0.21.0\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.8.0\n",
      "screen-resolution-extra==0.0.0\n",
      "seaborn==0.13.1\n",
      "SecretStorage==3.3.1\n",
      "selenium==4.15.2\n",
      "semantic-version==2.10.0\n",
      "Send2Trash==1.8.2\n",
      "sentencepiece==0.1.99\n",
      "sentry-sdk==1.30.0\n",
      "setproctitle==1.3.2\n",
      "shellingham==1.5.4\n",
      "shortuuid==1.0.11\n",
      "simplejson==3.19.2\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "sorcery==0.2.2\n",
      "sortedcontainers==2.4.0\n",
      "sounddevice==0.4.6\n",
      "soupsieve==2.3.1\n",
      "SQLAlchemy==2.0.25\n",
      "sqlitedict==2.1.0\n",
      "ssh-import-id==5.11\n",
      "stack-data==0.6.3\n",
      "starlette==0.35.1\n",
      "streamlit==1.29.0\n",
      "streamlit-drawable-canvas==0.9.3\n",
      "streamlit-drawable-canvas-jsretry==0.9.3\n",
      "streamlit-ext==0.1.9\n",
      "svglib==1.5.1\n",
      "sympy==1.9\n",
      "systemd-python==234\n",
      "tabledata==1.3.3\n",
      "tabulate==0.9.0\n",
      "tb-nightly==2.15.0a20231014\n",
      "tcolorpy==0.1.4\n",
      "tenacity==8.2.3\n",
      "tensorboard==2.14.0\n",
      "tensorboard-data-server==0.7.1\n",
      "termcolor==2.3.0\n",
      "terminado==0.17.1\n",
      "texify==0.1.8\n",
      "text-unidecode==1.3\n",
      "texttable==1.7.0\n",
      "thefuzz==0.20.0\n",
      "threadpoolctl==3.2.0\n",
      "tifffile==2023.9.26\n",
      "tiktoken==0.5.1\n",
      "timm==0.9.12\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.15.0\n",
      "tomesd==0.1.3\n",
      "toml==0.10.2\n",
      "tomli==2.0.1\n",
      "tomlkit==0.12.0\n",
      "tools==0.1.9\n",
      "toolz==0.12.0\n",
      "torch==2.1.0\n",
      "torch-grammar==0.3.3\n",
      "torchaudio==2.1.0\n",
      "torchdiffeq==0.2.3\n",
      "torchmetrics==1.2.0\n",
      "torchsde==0.2.6\n",
      "torchtyping==0.1.4\n",
      "torchvision==0.16.0\n",
      "tornado==6.3.3\n",
      "tox==4.12.1\n",
      "tqdm==4.66.1\n",
      "tqdm-multiprocess==0.0.11\n",
      "traitlets==5.13.0\n",
      "traits==6.3.2\n",
      "trampoline==0.1.2\n",
      "transformers==4.37.0\n",
      "trio==0.23.1\n",
      "trio-websocket==0.11.1\n",
      "triton==2.1.0\n",
      "tritonclient==2.41.1\n",
      "trlx @ git+https://github.com/CarperAI/trlx.git@3340c2f3a56d1d14fdd5f13ad575121fa26b6d92\n",
      "typeguard==4.1.5\n",
      "typepy==1.3.2\n",
      "typer==0.9.0\n",
      "types-python-dateutil==2.8.19.14\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.8.0\n",
      "tzdata==2023.3\n",
      "tzlocal==5.2\n",
      "ubuntu-advantage-tools==8001\n",
      "ubuntu-drivers-common==0.0.0\n",
      "uc-micro-py==1.0.2\n",
      "ufoLib2==0.13.1\n",
      "ufw==0.36.1\n",
      "unattended-upgrades==0.1\n",
      "unicodedata2==14.0.0\n",
      "uri-template==1.3.0\n",
      "urllib3==1.26.16\n",
      "usb-creator==0.3.7\n",
      "uvicorn==0.23.2\n",
      "validators==0.22.0\n",
      "virtualenv==20.25.0\n",
      "wadllib==1.3.6\n",
      "wandb==0.16.0\n",
      "watchdog==3.0.0\n",
      "wcwidth==0.2.12\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.2.3\n",
      "websockets==11.0.3\n",
      "Werkzeug==2.3.7\n",
      "whisper==1.1.10\n",
      "widgetsnbextension==4.0.9\n",
      "wrapt==1.16.0\n",
      "wsproto==1.2.0\n",
      "xdg==5\n",
      "xformers==0.0.22.post4\n",
      "xkit==0.0.0\n",
      "xxhash==3.3.0\n",
      "yacs==0.1.8\n",
      "yapf==0.40.2\n",
      "yarl==1.9.2\n",
      "zipp==1.0.0\n",
      "zstandard==0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc0eca-01a8-4640-9c05-33bb9ccfc292",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818295ab-2b6a-4621-be90-4c1c7093122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath=\"models/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "dataset_name=\"g-ronimo/oasst2_top1_en\"\n",
    "lr=0.00002      # learning rate\n",
    "bs=1            # batch size\n",
    "bs_eval=16      # batch size for evals\n",
    "ga_steps=16     # gradient acc. steps\n",
    "epochs=4\n",
    "max_length=2048      # samples max. length\n",
    "output_dir=\"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd920d4-6486-491f-afd7-f1c28d5cbb6c",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e867ab6-1b91-45a2-b08e-ec58cd433b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)    # fast tokenizer sometimes ignores added tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccbe5a-4ee1-4615-8e72-8d4103a315b7",
   "metadata": {},
   "source": [
    "# Add ChatML tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ece54e-49ef-4d8b-b957-8b2413eef555",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "    # pad_to_multiple_of=64)   # phi2 default is 64, see configuration_phi.py\n",
    "model.config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0f765-dd58-40d8-8648-abfe8d157c6c",
   "metadata": {},
   "source": [
    "# Load and prepare OA2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2dc07d-fddd-4c20-88ed-aeb5c4257ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2b498a2b394fcd85c6c138fdf7f2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/4877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc297dc17eb24b319cf7cee1c0db2445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/542 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "# Load Dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "# chatML Template and tokenize dataset\n",
    "templates=[\n",
    "    \"<|im_start|>assistant\\n{msg}<|im_end|>\",\n",
    "    \"<|im_start|>user\\n{msg}<|im_end|>\"\n",
    "]\n",
    "IGNORE_INDEX=-100\n",
    "\n",
    "# tokenize dataset, set input_ids and attention_mask to train on assistant outputs only\n",
    "def tokenize(input, max_length):\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "\n",
    "    for i,msg in enumerate(input[\"conversation\"]):\n",
    "        isHuman = msg[\"role\"]==\"user\"\n",
    "        msg_chatml=templates[isHuman].format(msg=msg[\"content\"])\n",
    "        msg_tokenized=tokenizer(msg_chatml, truncation=False, add_special_tokens=False)\n",
    "    \n",
    "        input_ids+=msg_tokenized[\"input_ids\"]\n",
    "        attention_mask+=msg_tokenized[\"attention_mask\"]\n",
    "        labels+=[IGNORE_INDEX]*len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids[:max_length],\n",
    "        \"attention_mask\": attention_mask[:max_length],\n",
    "        \"labels\": labels[:max_length],\n",
    "    }\n",
    "\n",
    "dataset_tokenized = dataset.map(\n",
    "    partial(tokenize, max_length=max_length), \n",
    "    batched=False, \n",
    "    num_proc=os.cpu_count(),    # multithreaded\n",
    "    remove_columns=dataset[\"train\"].column_names  # don't need this anymore, we have tokens from here on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d868b086-3863-40eb-a104-fb734bc355f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation'],\n",
       "        num_rows: 542\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f26ede-411e-4685-81f4-368a5ecc6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 542\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da59e2c-f190-4869-972a-9070c7e6de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }\n",
    "def collate(elements):\n",
    "    tokens=[e[\"input_ids\"] for e in elements]\n",
    "    tokens_maxlen=max([len(t) for t in tokens])\n",
    "\n",
    "    for i,sample in enumerate(elements):\n",
    "        input_ids=sample[\"input_ids\"]\n",
    "        labels=sample[\"labels\"]\n",
    "        attention_mask=sample[\"attention_mask\"]\n",
    "\n",
    "        pad_len=tokens_maxlen-len(input_ids)\n",
    "\n",
    "        input_ids.extend( pad_len * [tokenizer.pad_token_id] )   \n",
    "        labels.extend( pad_len * [IGNORE_INDEX] )    \n",
    "        attention_mask.extend( pad_len * [0] ) \n",
    "\n",
    "    batch={\n",
    "        \"input_ids\": torch.tensor( [e[\"input_ids\"] for e in elements] ),\n",
    "        \"labels\": torch.tensor( [e[\"labels\"] for e in elements] ),\n",
    "        \"attention_mask\": torch.tensor( [e[\"attention_mask\"] for e in elements] ),\n",
    "    }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c7357-6cdc-4355-9b7c-05aa518e214e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c35cf5-ae4f-432e-90a1-4469ed3125cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mg-ronimo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/g/TinyLlama-versus-StableLM2-dev/wandb/run-20240123_130351-dhl4fo1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g-ronimo/huggingface/runs/dhl4fo1k' target=\"_blank\">eager-puddle-57</a></strong> to <a href='https://wandb.ai/g-ronimo/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g-ronimo/huggingface' target=\"_blank\">https://wandb.ai/g-ronimo/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g-ronimo/huggingface/runs/dhl4fo1k' target=\"_blank\">https://wandb.ai/g-ronimo/huggingface/runs/dhl4fo1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='425' max='1216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 425/1216 13:18 < 24:53, 0.53 it/s, Epoch 1.39/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>1.440400</td>\n",
       "      <td>1.213814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "steps_per_epoch=len(dataset_tokenized[\"train\"])//(bs*ga_steps)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs_eval,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    eval_steps=steps_per_epoch,     # eval once per epoch\n",
    "    save_steps=steps_per_epoch,     # save once per epoch\n",
    "    gradient_accumulation_steps=ga_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    optim=\"paged_adamw_32bit\",      \n",
    "    learning_rate=lr,\n",
    "    group_by_length=False,\n",
    "    bf16=True,        \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=collate,\n",
    "    train_dataset=dataset_tokenized[\"train\"],\n",
    "    eval_dataset=dataset_tokenized[\"test\"],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
